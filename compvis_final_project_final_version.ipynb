{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9966151,
          "sourceType": "datasetVersion",
          "datasetId": 6130797
        },
        {
          "sourceId": 9984119,
          "sourceType": "datasetVersion",
          "datasetId": 6143975
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCHh_CudEQYE",
        "outputId": "3d35149f-6c66-482b-f4fc-3a047ac2c1a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.26.4)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.3.19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "import cv2\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from collections import defaultdict\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Dense,Flatten,Dropout\n",
        "from keras.applications.vgg16 import preprocess_input,VGG16\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import visualkeras\n",
        "from PIL import ImageFont"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:15:16.184014Z",
          "iopub.execute_input": "2024-11-23T19:15:16.184269Z",
          "iopub.status.idle": "2024-11-23T19:15:21.910274Z",
          "shell.execute_reply.started": "2024-11-23T19:15:16.184241Z",
          "shell.execute_reply": "2024-11-23T19:15:21.909513Z"
        },
        "id": "PCabOLv2eeRb"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "seed_constant = 10\n",
        "random.seed(seed_constant)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:15:56.156265Z",
          "iopub.execute_input": "2024-11-23T19:15:56.156966Z",
          "iopub.status.idle": "2024-11-23T19:15:56.160950Z",
          "shell.execute_reply.started": "2024-11-23T19:15:56.156927Z",
          "shell.execute_reply": "2024-11-23T19:15:56.160021Z"
        },
        "id": "MqVUIgM2eeRb"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:10.035837Z",
          "iopub.execute_input": "2024-11-23T19:16:10.036202Z",
          "iopub.status.idle": "2024-11-23T19:16:10.069435Z",
          "shell.execute_reply.started": "2024-11-23T19:16:10.036168Z",
          "shell.execute_reply": "2024-11-23T19:16:10.068547Z"
        },
        "id": "Sxn_qR6_eeRc"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -O imdb_crop.tar http://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n"
      ],
      "metadata": {
        "id": "KpVNgiPtffmu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar -xvf imdb_crop.tar"
      ],
      "metadata": {
        "id": "CDF_7Pu3fmqZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "# Load the metadata\n",
        "metadata_path = \"/content/imdb_crop/imdb.mat\"\n",
        "mat_data = loadmat(metadata_path)\n",
        "\n",
        "# Print all available keys in the .mat file\n",
        "print(mat_data.keys())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:10.071093Z",
          "iopub.execute_input": "2024-11-23T19:16:10.071633Z",
          "iopub.status.idle": "2024-11-23T19:16:14.796922Z",
          "shell.execute_reply.started": "2024-11-23T19:16:10.071603Z",
          "shell.execute_reply": "2024-11-23T19:16:14.795591Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k42fozceeRc",
        "outputId": "cfebccae-b35d-4525-e273-5bb0dbb8b472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'imdb'])\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the structure of 'imdb'\n",
        "import numpy as np\n",
        "imdb_data = mat_data[\"imdb\"]  # Extract the 'imdb' key\n",
        "print(type(imdb_data))        # Check the type of imdb_data\n",
        "print(imdb_data.shape)        # Check the shape\n",
        "print(imdb_data.dtype)        # Check the dtype\n",
        "\n",
        "# Explore the first entry of imdb_data to see its format\n",
        "print(imdb_data[0][0])        # The structure of the 'imdb' object"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:14.798012Z",
          "iopub.execute_input": "2024-11-23T19:16:14.798267Z",
          "iopub.status.idle": "2024-11-23T19:16:14.806205Z",
          "shell.execute_reply.started": "2024-11-23T19:16:14.798242Z",
          "shell.execute_reply": "2024-11-23T19:16:14.805248Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhWTN0WReeRc",
        "outputId": "b30bef4a-f679-44a2-dfeb-4a97dfbf019b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1, 1)\n",
            "[('dob', 'O'), ('photo_taken', 'O'), ('full_path', 'O'), ('gender', 'O'), ('name', 'O'), ('face_location', 'O'), ('face_score', 'O'), ('second_face_score', 'O'), ('celeb_names', 'O'), ('celeb_id', 'O')]\n",
            "(array([[693726, 693726, 693726, ..., 726831, 726831, 726831]], dtype=int32), array([[1968, 1970, 1968, ..., 2011, 2011, 2011]], dtype=uint16), array([[array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43'),\n",
            "        array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44'),\n",
            "        array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43'),\n",
            "        ...,\n",
            "        array(['08/nm3994408_rm926592512_1989-12-29_2011.jpg'], dtype='<U44'),\n",
            "        array(['08/nm3994408_rm943369728_1989-12-29_2011.jpg'], dtype='<U44'),\n",
            "        array(['08/nm3994408_rm976924160_1989-12-29_2011.jpg'], dtype='<U44')]],\n",
            "      dtype=object), array([[1., 1., 1., ..., 0., 0., 0.]]), array([[array(['Fred Astaire'], dtype='<U12'),\n",
            "        array(['Fred Astaire'], dtype='<U12'),\n",
            "        array(['Fred Astaire'], dtype='<U12'), ...,\n",
            "        array(['Jane Levy'], dtype='<U9'),\n",
            "        array(['Jane Levy'], dtype='<U9'),\n",
            "        array(['Jane Levy'], dtype='<U9')]], dtype=object), array([[array([[1072.926,  161.838, 1214.784,  303.696]]),\n",
            "        array([[477.184, 100.352, 622.592, 245.76 ]]),\n",
            "        array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]]),\n",
            "        ..., array([[  1,   1, 453, 640]], dtype=uint16),\n",
            "        array([[144.75225472, 126.76472288, 305.78804127, 287.80050943]]),\n",
            "        array([[457.524,  41.748, 518.016, 102.24 ]])]], dtype=object), array([[1.45969291, 2.5431976 , 3.45557949, ...,       -inf, 4.45072452,\n",
            "        2.13350269]]), array([[1.11897336, 1.85200773, 2.98566022, ...,        nan,        nan,\n",
            "               nan]]), array([[array([\"'Lee' George Quinones\"], dtype='<U21'),\n",
            "        array([\"'Weird Al' Yankovic\"], dtype='<U19'),\n",
            "        array(['2 Chainz'], dtype='<U8'), ...,\n",
            "        array(['Éric Caravaca'], dtype='<U13'),\n",
            "        array(['Ólafur Darri Ólafsson'], dtype='<U21'),\n",
            "        array(['Óscar Jaenada'], dtype='<U13')]], dtype=object), array([[6488, 6488, 6488, ..., 8410, 8410, 8410]], dtype=uint16))\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the nested structure within 'imdb'\n",
        "imdb_data = mat_data[\"imdb\"][0][0]\n",
        "\n",
        "# Extract each field\n",
        "dob = imdb_data[\"dob\"][0]              # Date of birth\n",
        "photo_taken = imdb_data[\"photo_taken\"][0]  # Year photo was taken\n",
        "full_paths = imdb_data[\"full_path\"][0]     # File paths to images\n",
        "names = imdb_data[\"name\"][0]               # Names of actors/actresses\n",
        "face_scores = imdb_data[\"face_score\"][0]   # Face detection scores\n",
        "celeb_ids = imdb_data[\"celeb_id\"][0]       # Celebrity IDs\n",
        "face_locations = imdb_data[\"face_location\"][0]  # Face locations\n",
        "\n",
        "# Print examples\n",
        "print(\"Date of Birth Example:\", dob[:5])\n",
        "print(\"Photo Taken Example:\", photo_taken[:5])\n",
        "print(\"Full Paths Example:\", full_paths[:5])\n",
        "print(\"Names Example:\", names[:5])\n",
        "print(\"Face Scores Example:\", face_scores[:5])\n",
        "print(\"Celebrity IDs Example:\", celeb_ids[:5])\n",
        "print(\"Face Location Example:\", face_locations[:5])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:14.808607Z",
          "iopub.execute_input": "2024-11-23T19:16:14.808961Z",
          "iopub.status.idle": "2024-11-23T19:16:14.820229Z",
          "shell.execute_reply.started": "2024-11-23T19:16:14.808922Z",
          "shell.execute_reply": "2024-11-23T19:16:14.819354Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_FN5MXheeRc",
        "outputId": "8b33c07d-ffcf-4e06-b5d2-1b682f5297f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date of Birth Example: [693726 693726 693726 693726 693726]\n",
            "Photo Taken Example: [1968 1970 1968 1968 1968]\n",
            "Full Paths Example: [array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43')\n",
            " array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44')\n",
            " array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43')\n",
            " array(['01/nm0000001_rm946909184_1899-5-10_1968.jpg'], dtype='<U43')\n",
            " array(['01/nm0000001_rm980463616_1899-5-10_1968.jpg'], dtype='<U43')]\n",
            "Names Example: [array(['Fred Astaire'], dtype='<U12')\n",
            " array(['Fred Astaire'], dtype='<U12')\n",
            " array(['Fred Astaire'], dtype='<U12')\n",
            " array(['Fred Astaire'], dtype='<U12')\n",
            " array(['Fred Astaire'], dtype='<U12')]\n",
            "Face Scores Example: [1.45969291 2.5431976  3.45557949 1.87211717 1.15876579]\n",
            "Celebrity IDs Example: [6488 6488 6488 6488 6488]\n",
            "Face Location Example: [array([[1072.926,  161.838, 1214.784,  303.696]])\n",
            " array([[477.184, 100.352, 622.592, 245.76 ]])\n",
            " array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]])\n",
            " array([[622.88550564, 424.21750384, 844.33900767, 645.67100587]])\n",
            " array([[1013.85900236,  233.88204221, 1201.5861278 ,  421.60916765]])]\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Convert Matlab serial dates to years for birth years\n",
        "def matlab_datenum_to_datetime(datenum):\n",
        "    matlab_epoch = datetime.datetime(1, 1, 1)\n",
        "    return matlab_epoch + datetime.timedelta(days=int(datenum) - 1)\n",
        "\n",
        "dob_years = [matlab_datenum_to_datetime(d).year if not np.isnan(d) else None for d in dob]\n",
        "\n",
        "# Calculate ages and filter valid samples\n",
        "ages = [photo - dob if dob is not None else None for photo, dob in zip(photo_taken, dob_years)]\n",
        "valid_indices = [i for i, age in enumerate(ages) if age is not None and age >= 0]\n",
        "\n",
        "# Filter valid data\n",
        "filtered_paths = [full_paths[i][0] for i in valid_indices]\n",
        "filtered_ages = [ages[i] for i in valid_indices]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:39.259736Z",
          "iopub.execute_input": "2024-11-23T19:16:39.260092Z",
          "iopub.status.idle": "2024-11-23T19:16:41.069268Z",
          "shell.execute_reply.started": "2024-11-23T19:16:39.260060Z",
          "shell.execute_reply": "2024-11-23T19:16:41.068541Z"
        },
        "id": "YDqjwybkeeRd"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a few examples of filtered paths and ages\n",
        "print(\"Example Path and Age Pairs:\")\n",
        "for i, (path, age) in enumerate(zip(filtered_paths, filtered_ages)):\n",
        "    print(f\"Path: {path}, Age: {age}\")\n",
        "    if i == 20:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg1o0yDqEZYP",
        "outputId": "683d4cf8-aa61-439a-9b7a-48671ab545f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Path and Age Pairs:\n",
            "Path: 01/nm0000001_rm124825600_1899-5-10_1968.jpg, Age: 68\n",
            "Path: 01/nm0000001_rm3343756032_1899-5-10_1970.jpg, Age: 70\n",
            "Path: 01/nm0000001_rm577153792_1899-5-10_1968.jpg, Age: 68\n",
            "Path: 01/nm0000001_rm946909184_1899-5-10_1968.jpg, Age: 68\n",
            "Path: 01/nm0000001_rm980463616_1899-5-10_1968.jpg, Age: 68\n",
            "Path: 02/nm0000002_rm1075631616_1924-9-16_1991.jpg, Age: 66\n",
            "Path: 02/nm0000002_rm1346607872_1924-9-16_2004.jpg, Age: 79\n",
            "Path: 02/nm0000002_rm1363385088_1924-9-16_2004.jpg, Age: 79\n",
            "Path: 02/nm0000002_rm1411175936_1924-9-16_1991.jpg, Age: 66\n",
            "Path: 02/nm0000002_rm1447271168_1924-9-16_2004.jpg, Age: 79\n",
            "Path: 02/nm0000002_rm1624085760_1924-9-16_2008.jpg, Age: 83\n",
            "Path: 02/nm0000002_rm1646056960_1924-9-16_1991.jpg, Age: 66\n",
            "Path: 02/nm0000002_rm221957120_1924-9-16_1974.jpg, Age: 49\n",
            "Path: 02/nm0000002_rm2287049216_1924-9-16_2007.jpg, Age: 82\n",
            "Path: 02/nm0000002_rm238734336_1924-9-16_1974.jpg, Age: 49\n",
            "Path: 02/nm0000002_rm2585828096_1924-9-16_2006.jpg, Age: 81\n",
            "Path: 02/nm0000002_rm2602605312_1924-9-16_2006.jpg, Age: 81\n",
            "Path: 02/nm0000002_rm2619382528_1924-9-16_2006.jpg, Age: 81\n",
            "Path: 02/nm0000002_rm2769394176_1924-9-16_2006.jpg, Age: 81\n",
            "Path: 02/nm0000002_rm2780403712_1924-9-16_2004.jpg, Age: 79\n",
            "Path: 02/nm0000002_rm2805435904_1924-9-16_1988.jpg, Age: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset directory\n",
        "img_dir = \"/content/imdb_crop\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:47.184263Z",
          "iopub.execute_input": "2024-11-23T19:16:47.185211Z",
          "iopub.status.idle": "2024-11-23T19:16:47.189362Z",
          "shell.execute_reply.started": "2024-11-23T19:16:47.185170Z",
          "shell.execute_reply": "2024-11-23T19:16:47.188145Z"
        },
        "id": "wpf9lRckeeRd"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "ioAAp2qXeeRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height=224\n",
        "img_width=224"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:49.752372Z",
          "iopub.execute_input": "2024-11-23T19:16:49.752753Z",
          "iopub.status.idle": "2024-11-23T19:16:49.756891Z",
          "shell.execute_reply.started": "2024-11-23T19:16:49.752718Z",
          "shell.execute_reply": "2024-11-23T19:16:49.755903Z"
        },
        "id": "kThmd7mDeeRd"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "def label_extraction(age):\n",
        "    '''\n",
        "    Categorize age into 5 classes:\n",
        "    0-20 --> 0, 21-40 --> 1, 41-60 --> 2, 61-80 --> 3, 81-100 --> 4\n",
        "    '''\n",
        "    if 0 <= age <= 20:\n",
        "        return 0\n",
        "    elif 21 <= age <= 40:\n",
        "        return 1\n",
        "    elif 41 <= age <= 60:\n",
        "        return 2\n",
        "    elif 61 <= age <= 80:\n",
        "        return 3\n",
        "    else:\n",
        "        return None  # Handles cases outside the range, if necessary"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:52.322389Z",
          "iopub.execute_input": "2024-11-23T19:16:52.323104Z",
          "iopub.status.idle": "2024-11-23T19:16:52.327652Z",
          "shell.execute_reply.started": "2024-11-23T19:16:52.323061Z",
          "shell.execute_reply": "2024-11-23T19:16:52.326634Z"
        },
        "id": "6Z9tm5HMeeRd"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing function\n",
        "def image_preprocessing(img_path):\n",
        "    '''\n",
        "    Reads, resizes, and normalizes the image.\n",
        "    '''\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found or invalid at path: {img_path}\")\n",
        "\n",
        "    # Resize and normalize\n",
        "    resized_img = cv2.resize(img, (img_height, img_width))\n",
        "    normalized_img = resized_img / 255.0\n",
        "\n",
        "    return normalized_img"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:17:04.979626Z",
          "iopub.execute_input": "2024-11-23T19:17:04.980373Z",
          "iopub.status.idle": "2024-11-23T19:17:04.985108Z",
          "shell.execute_reply.started": "2024-11-23T19:17:04.980338Z",
          "shell.execute_reply": "2024-11-23T19:17:04.984097Z"
        },
        "id": "G_oFnKDOeeRd"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "def balanced_subset(filtered_paths, filtered_ages, subset_size, label_func, num_labels=5):\n",
        "    # Categorize data by labels\n",
        "    label_groups = defaultdict(list)\n",
        "    for path, age in zip(filtered_paths, filtered_ages):\n",
        "        label = label_func(age)\n",
        "        if label is not None:\n",
        "            label_groups[label].append((path, age))\n",
        "\n",
        "    # Determine the subset size per label\n",
        "    subset_per_label = subset_size // num_labels\n",
        "\n",
        "    # Select equal samples for each label\n",
        "    filtered_paths_subset = []\n",
        "    filtered_ages_subset = []\n",
        "\n",
        "    for label in range(num_labels):\n",
        "        if label in label_groups:\n",
        "            samples = label_groups[label]\n",
        "            selected_samples = samples[:subset_per_label]  # Take the first N samples\n",
        "            filtered_paths_subset.extend([s[0] for s in selected_samples])\n",
        "            filtered_ages_subset.extend([s[1] for s in selected_samples])\n",
        "\n",
        "    # Combine paths and ages into the reduced dataset\n",
        "    return filtered_paths_subset, filtered_ages_subset"
      ],
      "metadata": {
        "id": "xTzN_yZhHYnE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset creation function\n",
        "def create_dataset(img_paths, img_ages):\n",
        "    '''\n",
        "    Preprocesses images and extracts labels for the dataset.\n",
        "    '''\n",
        "    features, labels = [], []\n",
        "\n",
        "    for img_path, age in zip(img_paths, img_ages):\n",
        "        # Construct full path\n",
        "        full_img_path = os.path.join(img_dir, img_path)\n",
        "\n",
        "        # Preprocess image and get class label\n",
        "        try:\n",
        "            preprocessed_img = image_preprocessing(full_img_path)\n",
        "            class_index = label_extraction(age)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping image {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        features.append(preprocessed_img)\n",
        "        labels.append(class_index)\n",
        "\n",
        "    return np.asarray(features), np.asarray(labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:17:06.799857Z",
          "iopub.execute_input": "2024-11-23T19:17:06.800605Z",
          "iopub.status.idle": "2024-11-23T19:17:06.806136Z",
          "shell.execute_reply.started": "2024-11-23T19:17:06.800569Z",
          "shell.execute_reply": "2024-11-23T19:17:06.805159Z"
        },
        "id": "zcOmXzuzeeRd"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dataset size by selecting a random subset of indices\n",
        "subset_size = 16000\n",
        "filtered_paths_subset, filtered_ages_subset = balanced_subset(\n",
        "    filtered_paths, filtered_ages, subset_size, label_extraction\n",
        ")\n",
        "\n",
        "# Optionally shuffle the subset for randomness\n",
        "shuffled_indices = np.random.permutation(len(filtered_paths_subset))\n",
        "filtered_paths_subset = [filtered_paths_subset[i] for i in shuffled_indices]\n",
        "filtered_ages_subset = [filtered_ages_subset[i] for i in shuffled_indices]\n",
        "\n",
        "# Create the reduced dataset\n",
        "features, labels = create_dataset(filtered_paths_subset, filtered_ages_subset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:17:09.681613Z",
          "iopub.execute_input": "2024-11-23T19:17:09.681978Z"
        },
        "id": "jIm-WoqYeeRd"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a few examples of the filtered dataset\n",
        "print(\"Example Dataset Samples:\")\n",
        "for i, (path, age) in enumerate(zip(filtered_paths_subset, filtered_ages_subset)):\n",
        "    print(f\"Path: {path}, Age: {age}, Label: {label_extraction(age)}\")\n",
        "    if i == 20:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgOy7lN6Hqhg",
        "outputId": "73e3e096-057a-47cb-a775-9cd9261ee04f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Dataset Samples:\n",
            "Path: 42/nm0000142_rm148670976_1930-5-31_2008.jpg, Age: 77, Label: 3\n",
            "Path: 04/nm0000704_rm3038878464_1981-1-28_2001.jpg, Age: 19, Label: 0\n",
            "Path: 06/nm0000106_rm1899874304_1975-2-22_2014.jpg, Age: 38, Label: 1\n",
            "Path: 13/nm0000213_rm3710160384_1971-10-29_1992.jpg, Age: 20, Label: 0\n",
            "Path: 12/nm0000112_rm3886334208_1953-5-16_2014.jpg, Age: 60, Label: 2\n",
            "Path: 02/nm0000102_rm643291648_1958-7-8_2013.jpg, Age: 54, Label: 2\n",
            "Path: 06/nm0000106_rm3418459648_1975-2-22_2009.jpg, Age: 33, Label: 1\n",
            "Path: 05/nm0000105_rm3609434624_1945-6-11_2005.jpg, Age: 59, Label: 2\n",
            "Path: 38/nm0001138_rm4066691072_1952-12-10_1970.jpg, Age: 17, Label: 0\n",
            "Path: 98/nm0000098_rm1163762432_1969-2-11_2005.jpg, Age: 35, Label: 1\n",
            "Path: 02/nm0000002_rm289065984_1924-9-16_1974.jpg, Age: 49, Label: 2\n",
            "Path: 64/nm0000164_rm2390858496_1937-12-31_2007.jpg, Age: 68, Label: 3\n",
            "Path: 63/nm0000663_rm2759170560_1980-8-12_2000.jpg, Age: 19, Label: 0\n",
            "Path: 93/nm0000093_rm157656832_1963-12-18_2013.jpg, Age: 49, Label: 2\n",
            "Path: 56/nm0000156_rm2751656448_1952-10-22_2015.jpg, Age: 62, Label: 3\n",
            "Path: 64/nm0000164_rm1843960064_1937-12-31_2003.jpg, Age: 64, Label: 3\n",
            "Path: 34/nm0000134_rm3064827392_1943-8-17_2009.jpg, Age: 65, Label: 3\n",
            "Path: 62/nm0000062_rm2018739456_1935-1-8_1966.jpg, Age: 30, Label: 1\n",
            "Path: 99/nm0000099_rm3962040832_1968-4-8_2015.jpg, Age: 46, Label: 2\n",
            "Path: 52/nm0000052_rm814923264_1924-9-28_1963.jpg, Age: 38, Label: 1\n",
            "Path: 10/nm0000110_rm3374747136_1960-12-10_1994.jpg, Age: 33, Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Extract labels for the subset\n",
        "subset_labels = [label_extraction(age) for age in filtered_ages_subset]\n",
        "\n",
        "# Count occurrences of each label\n",
        "label_counts = Counter(subset_labels)\n",
        "\n",
        "# Print the counts for each label\n",
        "print(\"Label Counts in the Dataset:\")\n",
        "for label, count in sorted(label_counts.items()):\n",
        "    print(f\"Label {label}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLz7IOp3KuZt",
        "outputId": "60430682-997a-4f85-9908-db942698e375"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Counts in the Dataset:\n",
            "Label 0: 3200\n",
            "Label 1: 3200\n",
            "Label 2: 3200\n",
            "Label 3: 3200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "encoded_labels = to_categorical(labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:14.908733Z",
          "iopub.status.idle": "2024-11-23T19:16:14.909017Z",
          "shell.execute_reply.started": "2024-11-23T19:16:14.908879Z",
          "shell.execute_reply": "2024-11-23T19:16:14.908894Z"
        },
        "id": "EXWhqcpueeRd"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test sets with stratification\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features,\n",
        "    encoded_labels,\n",
        "    test_size=0.1,\n",
        "    shuffle=True,\n",
        "    random_state=seed_constant,\n",
        "    stratify=labels  # Ensure equal distribution of labels\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:14.910381Z",
          "iopub.status.idle": "2024-11-23T19:16:14.910847Z",
          "shell.execute_reply.started": "2024-11-23T19:16:14.910608Z",
          "shell.execute_reply": "2024-11-23T19:16:14.910632Z"
        },
        "id": "BHTutk-oeeRd"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset information\n",
        "print(f\"Training features shape: {features_train.shape}\")\n",
        "print(f\"Testing features shape: {features_test.shape}\")\n",
        "print(f\"Training labels shape: {labels_train.shape}\")\n",
        "print(f\"Testing labels shape: {labels_test.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T19:16:14.912085Z",
          "iopub.status.idle": "2024-11-23T19:16:14.912560Z",
          "shell.execute_reply.started": "2024-11-23T19:16:14.912297Z",
          "shell.execute_reply": "2024-11-23T19:16:14.912323Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeU-Gn2deeRd",
        "outputId": "8981a17c-2a95-4cff-d0aa-5527916db9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: (11520, 224, 224, 3)\n",
            "Testing features shape: (1280, 224, 224, 3)\n",
            "Training labels shape: (11520, 4)\n",
            "Testing labels shape: (1280, 4)\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "Jx7Pc024msVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "QRrDYUB1mw92"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add preprocessing layer at the front of VGG16\n",
        "vgg = VGG16(input_shape=features_train.shape[1:], weights='imagenet', include_top=False)\n",
        "\n",
        "# Prevent training already trained layers\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add Flatten layer\n",
        "x = Flatten()(vgg.output)\n",
        "\n",
        "# Add Dense layers with weight regularization and dropout to reduce overfitting\n",
        "x = Dense(1000, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Dense layer with number of neurons equal to number of classes\n",
        "prediction = Dense(labels_train.shape[1], activation='softmax')(x)\n",
        "\n",
        "# Create the model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "VoTUEBazm0rA",
        "outputId": "a573d807-d1aa-48a5-9776-b7f6a8ca3dbe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │      \u001b[38;5;34m25,089,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m256,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │           \u001b[38;5;34m1,028\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,089,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">256,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,060,972\u001b[0m (152.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,060,972</span> (152.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,346,284\u001b[0m (96.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,346,284</span> (96.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import additional necessary libraries\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "# Create an instance of EarlyStopping callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Model checkpoint to save the best weights\n",
        "checkpoint = ModelCheckpoint(\"weights.best.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Callbacks list\n",
        "callbacks_list = [early_stopping_callback, checkpoint, reduce_lr]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Uj27sqr8m67m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Reduce learning rate with a more aggressive factor and smaller patience\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n",
        "\n",
        "# Early stopping with reduced patience\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Model checkpoint to save the best weights, monitoring val_loss\n",
        "checkpoint = ModelCheckpoint(\"weights.best.keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# Optionally add learning rate scheduler for warmup\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr * (epoch + 1) / 5  # Gradually warm up the learning rate\n",
        "    return lr  # After 5 epochs, use the base learning rate\n",
        "\n",
        "lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# TensorBoard for visualization\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
        "\n",
        "# Callbacks list\n",
        "callbacks_list = [early_stopping_callback, checkpoint, reduce_lr, lr_scheduler_callback, tensorboard_callback]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7pQsMxK1Qmht"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training the model\n",
        "history = model.fit(features_train, labels_train, epochs=50,\n",
        "                    shuffle=True, validation_split=0.1,\n",
        "                    callbacks=callbacks_list, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WKw0QHOnFfQ",
        "outputId": "532b3176-8c75-4135-e325-9a11533fef4c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2879 - loss: 3.7311\n",
            "Epoch 1: val_loss improved from inf to 3.18724, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.2881 - loss: 3.7291 - val_accuracy: 0.3707 - val_loss: 3.1872 - learning_rate: 2.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3763 - loss: 3.1800\n",
            "Epoch 2: val_loss improved from 3.18724 to 3.05635, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.3763 - loss: 3.1799 - val_accuracy: 0.4149 - val_loss: 3.0563 - learning_rate: 8.0000e-06\n",
            "Epoch 3/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3998 - loss: 3.0518\n",
            "Epoch 3: val_loss improved from 3.05635 to 2.98939, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.3998 - loss: 3.0518 - val_accuracy: 0.4340 - val_loss: 2.9894 - learning_rate: 4.8000e-06\n",
            "Epoch 4/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4295 - loss: 2.9821\n",
            "Epoch 4: val_loss improved from 2.98939 to 2.93730, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.4295 - loss: 2.9821 - val_accuracy: 0.4497 - val_loss: 2.9373 - learning_rate: 3.8400e-06\n",
            "Epoch 5/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4353 - loss: 2.9290\n",
            "Epoch 5: val_loss improved from 2.93730 to 2.88620, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.4353 - loss: 2.9288 - val_accuracy: 0.4479 - val_loss: 2.8862 - learning_rate: 3.8400e-06\n",
            "Epoch 6/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4420 - loss: 2.8723\n",
            "Epoch 6: val_loss improved from 2.88620 to 2.84800, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.4420 - loss: 2.8723 - val_accuracy: 0.4505 - val_loss: 2.8480 - learning_rate: 3.8400e-06\n",
            "Epoch 7/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4605 - loss: 2.8155\n",
            "Epoch 7: val_loss improved from 2.84800 to 2.80747, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.4605 - loss: 2.8155 - val_accuracy: 0.4531 - val_loss: 2.8075 - learning_rate: 3.8400e-06\n",
            "Epoch 8/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4706 - loss: 2.7713\n",
            "Epoch 8: val_loss improved from 2.80747 to 2.77335, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.4706 - loss: 2.7712 - val_accuracy: 0.4601 - val_loss: 2.7733 - learning_rate: 3.8400e-06\n",
            "Epoch 9/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4628 - loss: 2.7416\n",
            "Epoch 9: val_loss improved from 2.77335 to 2.73958, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.4629 - loss: 2.7414 - val_accuracy: 0.4661 - val_loss: 2.7396 - learning_rate: 3.8400e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4835 - loss: 2.7014\n",
            "Epoch 10: val_loss improved from 2.73958 to 2.70327, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.4835 - loss: 2.7013 - val_accuracy: 0.4679 - val_loss: 2.7033 - learning_rate: 3.8400e-06\n",
            "Epoch 11/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4980 - loss: 2.6427\n",
            "Epoch 11: val_loss improved from 2.70327 to 2.67305, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.4980 - loss: 2.6427 - val_accuracy: 0.4757 - val_loss: 2.6731 - learning_rate: 3.8400e-06\n",
            "Epoch 12/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5167 - loss: 2.6058\n",
            "Epoch 12: val_loss improved from 2.67305 to 2.64400, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.5166 - loss: 2.6058 - val_accuracy: 0.4835 - val_loss: 2.6440 - learning_rate: 3.8400e-06\n",
            "Epoch 13/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5205 - loss: 2.5772\n",
            "Epoch 13: val_loss improved from 2.64400 to 2.61973, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.5205 - loss: 2.5772 - val_accuracy: 0.4835 - val_loss: 2.6197 - learning_rate: 3.8400e-06\n",
            "Epoch 14/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5192 - loss: 2.5457\n",
            "Epoch 14: val_loss improved from 2.61973 to 2.59617, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5192 - loss: 2.5457 - val_accuracy: 0.4800 - val_loss: 2.5962 - learning_rate: 3.8400e-06\n",
            "Epoch 15/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5402 - loss: 2.5139\n",
            "Epoch 15: val_loss improved from 2.59617 to 2.57084, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.5402 - loss: 2.5139 - val_accuracy: 0.4948 - val_loss: 2.5708 - learning_rate: 3.8400e-06\n",
            "Epoch 16/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5378 - loss: 2.4803\n",
            "Epoch 16: val_loss improved from 2.57084 to 2.54940, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.5378 - loss: 2.4803 - val_accuracy: 0.4896 - val_loss: 2.5494 - learning_rate: 3.8400e-06\n",
            "Epoch 17/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5548 - loss: 2.4444\n",
            "Epoch 17: val_loss improved from 2.54940 to 2.53359, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5548 - loss: 2.4444 - val_accuracy: 0.4913 - val_loss: 2.5336 - learning_rate: 3.8400e-06\n",
            "Epoch 18/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5370 - loss: 2.4407\n",
            "Epoch 18: val_loss improved from 2.53359 to 2.51351, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5370 - loss: 2.4406 - val_accuracy: 0.4922 - val_loss: 2.5135 - learning_rate: 3.8400e-06\n",
            "Epoch 19/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5609 - loss: 2.4089\n",
            "Epoch 19: val_loss improved from 2.51351 to 2.49304, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.5610 - loss: 2.4088 - val_accuracy: 0.4913 - val_loss: 2.4930 - learning_rate: 3.8400e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5722 - loss: 2.3643\n",
            "Epoch 20: val_loss improved from 2.49304 to 2.47692, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.5722 - loss: 2.3643 - val_accuracy: 0.5113 - val_loss: 2.4769 - learning_rate: 3.8400e-06\n",
            "Epoch 21/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5779 - loss: 2.3414\n",
            "Epoch 21: val_loss improved from 2.47692 to 2.46378, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.5779 - loss: 2.3413 - val_accuracy: 0.5017 - val_loss: 2.4638 - learning_rate: 3.8400e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5998 - loss: 2.2989\n",
            "Epoch 22: val_loss improved from 2.46378 to 2.44504, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.5997 - loss: 2.2989 - val_accuracy: 0.5104 - val_loss: 2.4450 - learning_rate: 3.8400e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6077 - loss: 2.2749\n",
            "Epoch 23: val_loss improved from 2.44504 to 2.42959, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6077 - loss: 2.2750 - val_accuracy: 0.5148 - val_loss: 2.4296 - learning_rate: 3.8400e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6151 - loss: 2.2557\n",
            "Epoch 24: val_loss improved from 2.42959 to 2.41851, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6151 - loss: 2.2557 - val_accuracy: 0.5052 - val_loss: 2.4185 - learning_rate: 3.8400e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6113 - loss: 2.2400\n",
            "Epoch 25: val_loss improved from 2.41851 to 2.40786, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6113 - loss: 2.2400 - val_accuracy: 0.5087 - val_loss: 2.4079 - learning_rate: 3.8400e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6243 - loss: 2.2174\n",
            "Epoch 26: val_loss improved from 2.40786 to 2.39496, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6243 - loss: 2.2174 - val_accuracy: 0.5095 - val_loss: 2.3950 - learning_rate: 3.8400e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6263 - loss: 2.1989\n",
            "Epoch 27: val_loss improved from 2.39496 to 2.38465, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.6263 - loss: 2.1989 - val_accuracy: 0.5069 - val_loss: 2.3847 - learning_rate: 3.8400e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6444 - loss: 2.1664\n",
            "Epoch 28: val_loss improved from 2.38465 to 2.37190, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6443 - loss: 2.1664 - val_accuracy: 0.5113 - val_loss: 2.3719 - learning_rate: 3.8400e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6464 - loss: 2.1492\n",
            "Epoch 29: val_loss improved from 2.37190 to 2.36062, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6463 - loss: 2.1492 - val_accuracy: 0.5113 - val_loss: 2.3606 - learning_rate: 3.8400e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6534 - loss: 2.1289\n",
            "Epoch 30: val_loss improved from 2.36062 to 2.35724, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6534 - loss: 2.1289 - val_accuracy: 0.5078 - val_loss: 2.3572 - learning_rate: 3.8400e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6572 - loss: 2.1064\n",
            "Epoch 31: val_loss improved from 2.35724 to 2.34655, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6572 - loss: 2.1064 - val_accuracy: 0.5043 - val_loss: 2.3465 - learning_rate: 3.8400e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6752 - loss: 2.0886\n",
            "Epoch 32: val_loss improved from 2.34655 to 2.33910, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6752 - loss: 2.0886 - val_accuracy: 0.5234 - val_loss: 2.3391 - learning_rate: 3.8400e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6720 - loss: 2.0654\n",
            "Epoch 33: val_loss improved from 2.33910 to 2.33039, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6720 - loss: 2.0653 - val_accuracy: 0.5191 - val_loss: 2.3304 - learning_rate: 3.8400e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6889 - loss: 2.0358\n",
            "Epoch 34: val_loss improved from 2.33039 to 2.32431, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6889 - loss: 2.0358 - val_accuracy: 0.5252 - val_loss: 2.3243 - learning_rate: 3.8400e-06\n",
            "Epoch 35/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6924 - loss: 2.0273\n",
            "Epoch 35: val_loss improved from 2.32431 to 2.31624, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6924 - loss: 2.0272 - val_accuracy: 0.5200 - val_loss: 2.3162 - learning_rate: 3.8400e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6961 - loss: 1.9998\n",
            "Epoch 36: val_loss improved from 2.31624 to 2.30613, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.6960 - loss: 1.9998 - val_accuracy: 0.5191 - val_loss: 2.3061 - learning_rate: 3.8400e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7048 - loss: 1.9891\n",
            "Epoch 37: val_loss improved from 2.30613 to 2.29777, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7048 - loss: 1.9891 - val_accuracy: 0.5252 - val_loss: 2.2978 - learning_rate: 3.8400e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7010 - loss: 1.9727\n",
            "Epoch 38: val_loss improved from 2.29777 to 2.29329, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7010 - loss: 1.9726 - val_accuracy: 0.5156 - val_loss: 2.2933 - learning_rate: 3.8400e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7226 - loss: 1.9380\n",
            "Epoch 39: val_loss improved from 2.29329 to 2.28713, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7225 - loss: 1.9380 - val_accuracy: 0.5191 - val_loss: 2.2871 - learning_rate: 3.8400e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7317 - loss: 1.9233\n",
            "Epoch 40: val_loss improved from 2.28713 to 2.28338, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.7316 - loss: 1.9233 - val_accuracy: 0.5208 - val_loss: 2.2834 - learning_rate: 3.8400e-06\n",
            "Epoch 41/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7386 - loss: 1.8975\n",
            "Epoch 41: val_loss improved from 2.28338 to 2.27636, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7386 - loss: 1.8975 - val_accuracy: 0.5217 - val_loss: 2.2764 - learning_rate: 3.8400e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7479 - loss: 1.8748\n",
            "Epoch 42: val_loss improved from 2.27636 to 2.27501, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7479 - loss: 1.8749 - val_accuracy: 0.5278 - val_loss: 2.2750 - learning_rate: 3.8400e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7494 - loss: 1.8531\n",
            "Epoch 43: val_loss improved from 2.27501 to 2.26737, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7494 - loss: 1.8531 - val_accuracy: 0.5165 - val_loss: 2.2674 - learning_rate: 3.8400e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7501 - loss: 1.8579\n",
            "Epoch 44: val_loss did not improve from 2.26737\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.7501 - loss: 1.8579 - val_accuracy: 0.5200 - val_loss: 2.2708 - learning_rate: 3.8400e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7734 - loss: 1.8112\n",
            "Epoch 45: val_loss improved from 2.26737 to 2.25986, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7733 - loss: 1.8112 - val_accuracy: 0.5217 - val_loss: 2.2599 - learning_rate: 3.8400e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7767 - loss: 1.8030\n",
            "Epoch 46: val_loss did not improve from 2.25986\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.7767 - loss: 1.8030 - val_accuracy: 0.5130 - val_loss: 2.2642 - learning_rate: 3.8400e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7796 - loss: 1.7912\n",
            "Epoch 47: val_loss improved from 2.25986 to 2.25897, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7796 - loss: 1.7912 - val_accuracy: 0.5217 - val_loss: 2.2590 - learning_rate: 3.8400e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7813 - loss: 1.7702\n",
            "Epoch 48: val_loss improved from 2.25897 to 2.25821, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7813 - loss: 1.7702 - val_accuracy: 0.5304 - val_loss: 2.2582 - learning_rate: 3.8400e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m322/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7937 - loss: 1.7523\n",
            "Epoch 49: val_loss improved from 2.25821 to 2.25058, saving model to weights.best.keras\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7937 - loss: 1.7523 - val_accuracy: 0.5295 - val_loss: 2.2506 - learning_rate: 3.8400e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m323/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7936 - loss: 1.7383\n",
            "Epoch 50: val_loss did not improve from 2.25058\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.7936 - loss: 1.7383 - val_accuracy: 0.5226 - val_loss: 2.2540 - learning_rate: 3.8400e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights of the model with the best validation accuracy\n",
        "model.load_weights(\"weights.best.keras\")"
      ],
      "metadata": {
        "id": "H6vdFWxZnKg9"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_evaluation_history_base = model.evaluate(features_test, labels_test, batch_size=32)\n",
        "print(\"Test Loss:\", model_evaluation_history_base[0])\n",
        "print(\"Test Accuracy:\", model_evaluation_history_base[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v17erTinKLc",
        "outputId": "f2bb9fd4-8dd9-44aa-eab3-2fc40862ad94"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5455 - loss: 2.2300\n",
            "Test Loss: 2.253497362136841\n",
            "Test Accuracy: 0.534375011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"compvis_age_predictor_model.keras\")"
      ],
      "metadata": {
        "id": "Az_Lrv9FnO9N"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('compvis_age_predictor_model.keras')\n",
        "\n",
        "# Define the image preprocessing function\n",
        "def image_preprocessing(img_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # Resize the image to 224x224 (as expected by VGG16)\n",
        "    resized_img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Normalize the image\n",
        "    normalized_img = resized_img / 255.0\n",
        "\n",
        "    # Convert image to array with the required shape (224, 224, 3)\n",
        "    img_array = img_to_array(normalized_img)\n",
        "\n",
        "    # Expand dimensions to make it compatible with the model input (batch size of 1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Define the function to map the predicted class index to the age range\n",
        "def map_class_to_age(class_index):\n",
        "    # Age ranges for the class indices\n",
        "    age_ranges = {\n",
        "        0: \"0-20\",\n",
        "        1: \"21-40\",\n",
        "        2: \"41-60\",\n",
        "        3: \"61-80\"\n",
        "    }\n",
        "\n",
        "    return age_ranges.get(class_index, \"Unknown\")\n",
        "\n",
        "# Function to predict the age group of a given image\n",
        "def predict_age(img_path):\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = image_preprocessing(img_path)\n",
        "\n",
        "    # Predict the class (age group)\n",
        "    predictions = model.predict(preprocessed_image)\n",
        "\n",
        "    # Get the index of the class with the highest probability\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Map the predicted class index to the corresponding age range\n",
        "    predicted_age_range = map_class_to_age(predicted_class_index)\n",
        "\n",
        "    return predicted_age_range\n",
        "\n",
        "# Example usage: predict the age group of a given image\n",
        "img_path = '/content/premium_photo-1668806642968-c6bebdab7c4c.jpg'  # Replace with the path to your image\n",
        "predicted_age = predict_age(img_path)\n",
        "\n",
        "print(f\"Predicted Age Range: {predicted_age}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw6GJCEUoyfW",
        "outputId": "a221a970-611d-4b99-fb6e-6c77cec6641d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n",
            "Predicted Age Range: 0-20\n"
          ]
        }
      ]
    }
  ]
}